# 2023-07-05 Lecture online

### Audrey Tang:

Thank you. Thank you for the very kind introduction.

I'm delighted to already receive 10 questions before the talk.

Since we already started highlighting the first one, I will just proceed to answer the question, but feel free to raise your hands and ask follow up questions and continue to post or press like on Slido.

The first question asks about my background. As you can see, my background is very transparent.

It's documented that I participated very early on in the free software communities since '94, '95.

I was a junior high school student back then, the eighth grade, and then I dropped out of junior high school because I told the head of my school that I get to do research on this new thing called the World Wide Web and I don't have to study for 10 more years to get a PhD or something before doing research. I can do research 16 hours a day instead of just doing it eight hours after school.

The principal was very understanding and agreed that I could homeschool and did not need to join her in the class anymore.

So my focus was on swift trust, how people come to trust each other quickly on the internet. And so very quickly, when I was 16, I co-founded one of Taiwan's more highlighted startups during the dot-com era, doing full-text search, doing instant messaging, doing C2C, like eBay auction and many other things.

And then I discovered the open source movement in '98, and then I just put all my energy in, including working on the new computer languages, Perl and Haskell and things like that.

And then I worked as a consultant with Apple's Siri language technology team for six years, as well as with Oxford University Press and many other startups.

Then in 2014, the people in Taiwan had a large-scale deliberation on the street, with half a million people on the street and many more online. It was called the Sunflower Movement.

People deliberated, among other things, whether to admit so-called private sector equipment from PRC into our then new 4G telecommunication network.

The Occupy for three weeks was peaceful and nonviolent. I supported -- along with many other people -- the live streaming, the facilitation, many of the tools that we now take for granted, like live streaming and so on, we pioneered its use in large-scale demonstration so that the 20 or so NGOs, civil society organizations, agreed on a set of very coherent demands at the end of the three-week Occupy, which is very rare in Occupy movements to converge to a very coordinated sense of rough consensus.

At the end of that year, the national government in Taiwan said that open government data participation is going to be the national direction. I was hired as a young reverse mentor to advise the cabinet.

After a couple of years working with the cabinet, doing crowdsource regulation on Uber, Airbnb, a lot of technologies, emerging ones, I then got promoted to full-time minister in 2016 when Dr. Tsai Ing-wen became the president of Taiwan.

I've been serving now seven years or more as the digital minister.

Just last year, after the pandemic, we reorganized to have a ministry of digital affairs that takes all the agencies that work closely on informatics during the pandemic, and put them into the same ministry.

So we have participation, as I mentioned. We have progress, like platform economy, AI, and so on. And we have security, like cybersecurity, and testing and verification, and so on, which all three used to belong in different ministries.

But as of last August, we brought them all together into a new ministry, the ministry of digital affairs.
Our main idea is digital resilience for all, meaning that participation, progress, and safety need to be taken as a more and more overlapping concern within our ministry and within the government, instead of having them to be opposite or polarized values whenever emerging technology comes.

So that's like my three-minute elevator pitch. I hope that answered this question. If there's any follow-up, please ask. Otherwise, I'll just move on to the next.

> (interviewer speaks)

### Audrey Tang:

What would I say to encourage girls to learn and work in information technologies? Interestingly, because in Mandarin, we translate "程式設計," programming, as program design or software design, instead of software engineering.

So we have a very healthy balance of boys and girls, because many people consider design as something that's closer to people instead of just engineering, which is closer to machines. At some places, we even need to encourage boys to get into design because of the other way of gender imbalance.

But there is a specific subdomain in programming that has significant gender imbalance, which is cybersecurity. Admittedly, I think a majority of hardcore cybersecurity practitioners are still men.

Previously, the young women, if they say during their high school years that they want to be a hacker, white hat researcher, and so on, usually it's kind of frowned upon by their parents because hacking was associated criminal activity, and things like that.

So that is the one subdomain within our field that still has more than usual gender imbalance. To counter that, a few years ago, four years ago, the head of Taiwan's largest cybersecurity public traded company, Trend Micro, was a woman, and I'm non-binary. We recorded [videos](https://gics.tw/Achievement_Video) to promote what we call Girls in Cybersecurity.

To date, there's thousands of high school and young undergraduate women that specialize in this program because the president herself gives an award, the science minister, the digital minister, everyone gives a high level of legitimacy so that they become national heroes defending our nation -- because we do face a lot of cyberattacks -- instead of being associated with criminal or shady business.

I was on a promotional video saying that biology should not determine destiny. When I learned programming, the computer never cared about my gender. So if you're interested in that slightly humorous comedic film, I can send it afterwards after this conversation as a supplementary material.

Thank you.

> (interviewer speaks)

### Audrey Tang:

I think the main difference I see is that in many other jurisdictions, the digital ministers focus on, as I mentioned, to make the progress and safety harmonize.

Like during COVID, you need to have the economic prosperity, but you also need to take care of people's health. You need to take care of civil liberties and privacy, but you do actually need to trace the contacts of the virus.

There are many dilemmas between safety on one side and liberty on the other that needs careful balancing in the realm of digital. In that, we are the same with the jurisdictions this question asks.

But in the moda, in our ministry, these two concerns reside in the administration for digital industries and the administration for cybersecurity, respectively, so progress and safety.

But above both administrations is the ministry itself. And the ministry specifically has participation -- civic participation, social entrepreneurship -- as our main mandate.

So we have this overarching goal of the government not coming up with all the good ideas, but rather just providing as open source, as open data, as open API, so that people in the grassroots, in the civil society who are not even registered companies, they could be a co-op, an association, a union, and so on.

Then they come up with better contact tracing methods, better vaccination registration workflows, better mask rationing methods. That's proved to be nimble enough, agile enough, because if we empower people closest to the pain, we get innovation much faster than if we just empower the people who are not on the front line, not close to the pain.

I think participatory democracy and a sense of collective intelligence are our main differentiators compared to most other jurisdictions with a digital ministry.

> (interviewer speaks)

### Audrey Tang:

The next one, how would I ideally envision Taiwan's digital field implementation?

This is asking for my job description. It so happens that I wrote my own job description because Taiwan did not used to have a digital minister. So my job description is pinned on my Twitter, which I will simply recite. That is my vision for the past seven years and hopefully many more years after this.

It goes like this:

When we see internet of things, let's make it an internet of beings.

When we see virtual reality, let's make it a shared reality.

When we see machine learning, let's make it collaborative learning.

When we see user experience, let's make it about human experience.

Whenever we hear that a singularity is near, let us always remember the plurality is here.

Plural and Digital are the same word in Taiwanese Mandarin. I'm a digital minister, but I'm also the plural minister, our minister of plurality.

To focus on plurality or collaborative diversity enabled by digital technologies instead of digital technologies taking away collaboration, taking away diversity. This is the main idea.

Instead of democracy and technology going further and further apart, plurality brings them together. And this is why we call ourselves 數位部, literally a ministry of digital affairs. I hope that answers the question.

> (interviewer speaks)

### Audrey Tang:

How far would I rate Taiwan on achieving such a vision? I would say that the three years of pandemic and the associated infodemic, meaning the information manipulation, interference, overwhelming of information and so on, showed that Taiwan has a higher than usual resilience when faced with societal challenges to figure out quicker than usual solutions.

Even when we faced literal attacks last August, the highest cyber attack Taiwan has ever seen, along with missiles flying over our head and so on, still, the societal resilience was commendable. We very quickly closed the cybersecurity exploits. The stock market totally did not crash, but rather actually grew that day.

This March, when Dr. Tsai Ing-wen, our president, visited the US, we faced a very similar volume of attack, and then we successfully countered it.

Whether it is foreign information manipulation interference, or cyberattacks, or the coronavirus, or adversarial generative AI, I think the idea is not to achieve a point of existence, but rather to have this mutual trust, the fabric of trust between government, the civil society and the industry, so that on each incoming challenge, we trust each other enough to solve this issue together.

So I would say the societal resilience rate, the readiness level in Taiwan is very high at this moment.

> (interviewer speaks)

### Audrey Tang:

Our main work, 2016-17, was to take the civil society collaboration, such as vTaiwan that we did 2014-15, and institutionalize this collaborative process.

To that end, starting 2017, in each of our ministries, we have more than 30 ministries, and each minister has a team of what we call participation officer in charge of engaging the public, sometimes engaging with comedians to facilitate communication, but also to facilitate listening as well.

This focus on civic participation, I think, has been instrumental in helping us to overcome some of what could have been the most divisive issues in Taiwan.

For example, we are is still the only country in Asia to have legalized marriage equality. We managed to avoid alienating half of the population either way, but rather finding a creative solution through civic participation and referenda and so on, so that same-sex people marry as individuals, as the bylaws, but not the in-laws, not the father-in-law, mother-in-law, so they don't form kinship, familial lineage relationships.

This very eclectic solution appealed to both sides of people, so that we now have a very high, I wouldn't say tolerance, but rather acceptance rate for marriage equality and many other things as well.

I would say, yes, co-creation, co-designing with the civil society instead of a top-down nudge only mentality is broadly shared by all ministries in our cabinet.

> (interviewer speaks)

### Audrey Tang:

That actually closely relates to the next question. The next question asks, how important is the notion of openness?

I would say it's absolutely central, because if we do not embrace openness and instead insist on copyright restrictions and so on, then only the first innovator gets to innovate.

Once they join procurement, become part of the government ecosystem, only the initial inventor gets to do maintenance and enhancements and so on.

So it will be a closed ecosystem. But because we insist on open interoperability, anyone, as I mentioned, closer to the pain, have access to the same data. And it also changes the political dynamics.

One example, during the pandemic in 2020, we started rationing out masks very early on. Then a opposition party MP, now the mayor of Hsinchu, who was an MP at the time, Ann Kao, asked the Minister of Health and Welfare, saying, you say that each person on average is of the same distance of a nearby pharmacy, so everybody have the same chance, same effort to reaching this mask distribution.

But the OpenStreetMap community showed Ann Kao, using a visualization, that we only counted in kilometers, but not in travel time. So it actually biases a lot for people closer to metro or very convenient transportation. And people who have to wait for hours to get a bus doesn't get masks because it was unevenly distributed according to opportunity cost of time.

Now if we had not been publishing as real-time open data, this distribution evidence, it will feel like the opposition making a critique of the ruling party. But because we have been making all these numbers available for independent analysis, Minister of Health and Welfare simply said, legislator, you are a expert in big data, so teach us how to do it, and we will change next week to your algorithm.

So sharing the evidence with opposition parties, indeed with everyone, enables a co-creating dynamic among all the parties, making it a pan-partisan thing. This is the best for the career public service because it removes the risk of discontinuity when different parties come to administer a seat and so on.

By removing the risk and increasing the possibility of innovation for civil society, we build alliance with the career public service to embrace open data and open API and so on because the issues of data quality and so on are taken care of by our procurement laws directly.

We say those data form and data pipeline and so on are part of public infrastructure. Not just things made out of concrete like bridges or whatever can qualify as public infrastructure in Taiwan since 2016, we've started classifying this kind of data pipeline and so on as for looking infrastructure as well.

So taking one of the most cost-sensitive centers away from the public service and simply saying, let's just invest in open data pipelines as a public infrastructure that benefits all.

> (interviewer speaks)

### Audrey Tang:

In the field of cybersecurity, Claude Shannon, one of the founders of information theory, had a maxim: "The enemy already knows the system." You need to assume that the enemy already knows the system anyway, instead of relying on obscurity.

Because the reason is if you defend only a little bit of very highly sensitive data, for example, the passkey or the biometric chip on the device or the zero trust architecture, then the surface you defend is just your fingerprint, your device, your connectivity. So it's easy to focus the defense on this.

But if you focus your attention not just on the system, but also on the obscurity of the system, relying on the enemy not knowing the components of your system, then it actually makes it harder to defend. Maybe harder to defend than if you just defended the confidential data in the first place, because you have to now defend millions of lines of secret software.

So we embrace the idea of public code, of verifiable software, bill of material, so open source components, but ones that passed security testing, penetration testing, and so on. We don't blindly just take the latest upgrade from open source libraries into our public service, of course. We do hardening, penetration testing, and so on.

At the end of the day, we assume the enemy already knows our system anyway, and so we are not shying away from publishing.

For example, the entire back end and front end of our website, moda.gov.tw, which went online the same hour as the missile started flying over our head last August. I actually went to the press saying that because we use Web3, interplanetary file system, a new way of designing websites, we don't suffer one second of downtime when they attack us.

Anyone, anywhere in the world can use IPFS to download our website, to pin our website like BitTorrent, and share the load to keep us afloat. Using this kind of cryptographically hardened software from the Web3 world assumes open source, because the source code runs on your collaborator's computer as well.

So it's a very different way of thinking about security, security through democratic participation. I hope that answers your follow-up question.

> (interviewer speaks)

### Audrey Tang:

Yes. We have what, half an hour left, but this is a half-day topic, so I will be very brief.

The position regarding AI, I did sign along with around 300 people, this extinction risk statement that compares the abuses of AI to that of pandemic or nuclear proliferation. To me, these three are of similar risk level. The climate, of course, above them all.

So still not more urgent than climate, but similar urgency as pandemic and nuclear proliferation.

AI, especially generative AI, poses this immediate risk of deepfaking, synthesizing media. My voice model, my image, my way of writing and speaking, language model, and so on, has increased because I publish everything as a transcript. Everybody can easily train a clone of me, a deepfake version, and it would be almost impossible to tell the difference.

I know because I reply to my emails using a model that I trained on my MacBook locally, and it's getting really good. So you can thank the model for agreeing to your invitation for me to speak today... of course, I read the reply before hitting send.

But the point I'm making is that because of open source AI, this capability is literally in everyone's hands, which is why we're so insistent on zero trust and on passwordless authentication, because we have to assume that anything can be transmitted through a telephone line will be transmitted because voice cloning, scams, social engineering, phishing attacks will probably succeed with a very high success rate, given this newfound open source capability of deepfaking.

We need to adapt our societal resilience, and we need to regulate to clearly say as those abuses start proposing risk to clearly signify that they're not to be tolerated.

Taiwan has already passed three law amendments in response to generative AI outlawing, for example, deepfaking for pornography, deepfaking to have an imposter of investors advice to con people, to scam people into investment.

If any social media do not implement digital signature or provenance verification for those investment advertisements, they are liable for the same damage as the scammers have caused to the society.

Finally, of course, deepfaking during elections is also banned. And so we will clearly delineate those abuses as such as abuses and to address the risk using again, collective intelligence.

As we speak, we are now running a Polis conversation, which is an interactive poll that asks people to answer yes or no questions. Do you think this is a risk or do you think this is good or not? Anyone can also write their own statements.

Like Slido for other people to vote on and the result will be fed into a face to face deliberation actually to similar to, I don't know, you have civic assemblies too, right? I read about the end-of-life deliberation and things like that.

So a professionally facilitated conversation based on the input from the collective intelligence online, and then we plan to take the entire transcript and feed it into our national language model, the TAIDE.

The hope is that we will teach the AI as a coach so that it can turn this consensus into a curriculum to teach future AIs so that we can democratically align any language model by training a low rank adapter that makes the new model behave according to the collective will during the deliberation and the rough consensus.

This is like co-creating a curriculum to raise a child or co-create a naturalization curriculum for immigrants to naturalize to the society. We have to co-domesticate with these new language models, these tools.

So if you're interested in more details, this is called Alignment Assemblies from the Collective Intelligence Project. We're working with OpenAI and Anthropic and many other labs on this process.

> (interviewer speaks)

### Audrey Tang:

The next one is about privacy. Is the Taiwan data protection law subject to change?

Good news, it's freshly changed. The parliament finally passed the clause that says we are to have an independent data protection authority. So later next month, it will begin to form. By next year, as demanded by our constitutional court, we will have a GDPR-compliant independent DPA, finally, after 10 years.

So I'm very happy about that because I do believe that if people do not thoroughly anonymize to a zero knowledge degree, the data, the personal data, and make a very clear delineation between personal data and not personal data, but instead focus on something that's like in between, partially de-identified data, anonymous data, etc., then that actually decimates the trust of the society.

Because as soon as one data breach, one misuse, or one abuse makes the headlines, then people would not voluntarily contribute their personal data to a thoroughly anonymizing process to contribute to public good.

But as we have seen during the pandemic, if we have good and zero knowledge design, people do voluntarily participate in effective contact tracing and many other data altruism projects that didn't work if we lose the trust of the people. To me, the trust of the people is paramount.

To give no trust is to get no trust. So the government need to first trust the people before expecting trusting back. The way we trust the people is to make sure that we publish as open data and so on thoroughly non-personal data.

We work with the latest technologies like homomorphic encryption, synthetic data, zero knowledge proofs and so on to ensure that even the adversary has a quantum computer, they cannot derive the original personal data if they participate in this shared open data research.

This is especially important with AI, because if you're not information theoretically secure and private, there exists some generative AI that can de-identify it much easier than humans would even before quantum computer arrives.

So I would say yes, because of generative AI and scams and deep fake and things like that, we need to now take a zero knowledge stance when it comes to de-identifying data into thoroughly non-personal data.

We even invented a new word, "非個資數據", thoroughly non-personal data, to describe this change.

> (interviewer speaks)

### Audrey Tang:

The next one is, can you see some opportunity to develop a common e-gov software framework with other countries? Well, the French trained language model, BLOOM, the BigScience model, is already a basis of Taiwanese language model innovation. So we thank you for that.

And we also work on the same communication software as I understand there are also French contributions, the Matrix/Element secure communication system. So it's like Signal, but everybody can host it themselves. We use that in our emergency response program.

This is not a hypothetical situation; it actually happened earlier this year when all two subsea cables between Taiwan and Matsu Island were "accidentally" cut by PRC vehicles. The island was without subsea cables, so we need to fall back to microwave and satellites.

In those scenarios, a truly federated messaging network is very important. So we have just tested the Element/Matrix framework when it comes to decentralized communication. It works very well, pass with flying colors.

So I thank the French investment into Element/Matrix as part of your way to be liberated from vendor lock-in.

In addition to that, we work closely with the UK GDS, the government digital service in the United Kingdom. So we translated GDS Forms and GDS Notify. We work very closely with their design system team so that when you go to our website, it looks exactly the same as gov.uk because we use the same design system, what we built based on them.

Now there are also talks to work with the Estonian reinterpretation of the Ukrainian Diia system, which is the super app for resilience that the Ukrainians have used very successfully over the past year and a half and so on.

So there's a very vibrant people-to-people connection across jurisdictions. Because we embrace civil society contributions, they naturally make way into our communication.

> (interviewer speaks)

### Audrey Tang:

Yes, I totally agree. Taiwan has our own system, the TWQR, that integrates the scanning to pay QR codes together.

We are also working closely with Japan, the digital agency people, making standards interoperable. I think it's not about software though, because it's very likely that the individual banks and payment companies and so on would develop their own software.

Open source makes slightly less sense in this regard, maybe just as a reference implementation. What is important here is a shared infrastructure and a shared QR code and the standards interoperable levels of data exchange. I think that is the focus we can all work on together in this particular domain.

> (interviewer speaks)

### Audrey Tang:

What do I think countries should do to avoid the Orwellian risks associated with the digitalization of public services and AI risk?

So when I said contact tracing, many people have in mind some Orwellian way of the state knowing everywhere you went and so on, but that's not where Taiwan is doing.

When we say transparency, we always mean how the state works is transparent to the citizen. We never mean the citizen transparent to the state. This is an important distinction.

Taiwan's civil society invented the contact tracing method called 1922 SMS. It's very easy to explain. You visit any venue and that venue prints this random code, a QR code in its front door. But just like this slide of screen you're looking at, it's actually also in clear text.

So what the QR code represents is 15 random numbers and you can manually, like my grandma can manually tweet SMS those 15 numbers to 1922, the well-known number in your telecom for pandemic services. Everybody can see you just scan the QR code, press send, and then the 15 digit goes to your own telecom company.

This has two properties.

First, the venue just checks you have sent a message, but they don't learn anything about your phone number. They don't learn anything about you.

Second, your telecom learns about your phone number, but they already know. And they learn this 15 digit random number, but they don't know which venue it corresponds to.

So this kind of double-blind, oblivious, zero-knowledge design is a privacy enhancing technology ensures that nobody learns more about you than what they already know.

When there is a community break, it can recursively send out SMS notifications for exposure notification, but everyone can also go on a website to check which municipality, which contact tracing team have looked at your data and use it in such a way for contact tracing or exposure notification.

There's accountability even when there is a community outbreak and exposure notification is sent. This like a microcosm shows our main principle, which is to have the public safety along with the civil liberties and privacy.

We're not making trade-offs. We want to use zero knowledge and cryptography to ensure that both are taken care of at the same time.

So this is how we avoid the risk is inviting the human right groups, the civic technologists, the people who care the most about privacy to invent such a system and the state just adopts it.

> (interviewer speaks)

### Audrey Tang:

Yes. So we had SARS, the previous version of COVID in 2003. And after that, we switched to IC cards for universal healthcare. Not just citizens, our residents all have a universal health services along with the IC card that identifies them.

Although there is such an IC card, it can only be used for public service. It must never be used for commercial transactions and things like that. Later on, we also developed the app version of that, the National Health Insurance Express app.

During the COVID, that became the super app. So you will book for a vaccine on that, you will book for masks and other PPEs on that, you will be confirmed as positive on that, and then just video conference with the pharmacist or things like that, all within that super app dedicated for health issues.

It's partly thanks to that, that we never had a single day of lockdown. During the three years of the pandemic, moving between city and city was always possible in Taiwan. We never got so bad so that we have to require shutting down entire cities or districts.

I think voluntary participation through the National Health Insurance System, I think it was key in avoiding both the Orwellian risk, but also the other risk of pandemonium of people just doing whatever they want and spreading the virus.

> (interviewer speaks)

### Audrey Tang:

Given the increase in budgets, technical means and powers of large district companies, what should be, in my opinion, the position that a state should adopt in terms of regulations of over-deployment and also negotiations?

This is an excellent question. What we have found is that those large companies do listen to the civil society if there is a credible threat of social sanction and there is a credible alternative solution.

For example, in 2018, we discovered even though Taiwan has a very good fact-checking ecosystem for real-time response to the trending not coronavirus, mild virus, people voluntarily report the foreign interference even into encrypted channels.

For the most trending ones, people also collaborate voluntarily to give context. Then we adopt a notice and public notice way so that when professional fact-checkers verified the context supplied by the crowd, a mandatory notice restoring the context like Twitter community note is posted.

But Facebook was selling bypass-fact-checking as a service. If you just buy advertisements, sponsored ads, it bypasses this entire ecosystem of fact-checking. Closer to the 2018 election, there's a lot of foreign purchases of targeted advertisements in Taiwan along with social or political campaigns doing micro-targeting and there was absolutely no visibility.

So the domestic counterparts to Facebook passed the self-regulation to basically treat sponsored ads as political campaign donation, which in Taiwan means you have to publicly publish the details. foreign people are banned from buying such things, just as they cannot donate to political campaigns.

When they adopted this accord on their own, the civil society gave Facebook an ultimatum saying that we have seen what you have done and we have, the civil society, have worked with the government, actually pressured the government into adopting the Sunshine Laws and Open Data Laws on political campaign donations. So now we're doing the same to you. If you do not clean up your mess in 2019, then we're going to have a large-scale social sanction.

So Facebook in 2019 implemented, I think, one of the first jurisdictions, the full civic integrity measures. Now they're enrolling in more jurisdictions, but at the time, specifically because they know if they don't comply, there is a real chance of social sanctioning.

So I would say it's just like a trade negotiation. If the citizens are on your side, if the consumer protection, the unions and co-ops are on your side, it's not a difficult game.

But if your population does not yet understand the critical details, like in 2014 when people generally didn't understand that PRC vendors carry this risk, then society-wide deliberations are a great way for people to become aware of such issues.

> (interviewer speaks)

### Audrey Tang:

What do I think about France's level of e-government services? I think your level is very good. I consistently see you placed in the top open data or smart city application indexes. In terms of delivering services to the citizens, I think you are obviously very capable.

My main learning when I was becoming the digital minister in 2016, I actually spent 12 months before that, six of which was in Paris. So I was like almost moving to Paris before I joined the cabinet. I witnessed firsthand the first rounds of République Numérique consultations, the participatory budgeting exercise and many exercises that led to Nuit debout, among many other things.

So we have seen solidarity between the civic technologists on one side and the reformers, the public service on the other side. To me, that's always the most important thing.

It's not the parties, not the ideologues, but rather whether we, the civic technologists and the career public service, see each other as complementary forces, as alliances.

In Taiwan, we spent 10 years building this solidarity. I see a very similar dynamic back then when I visited Paris in 2016. As long as we keep on such a route, bringing as alliances, civil society, civic tech to the career public service and vice versa, so not just fellows into the government, maybe also fellows into the civil society organizations, as long as we keep this kind of conversation going, I think it's definitely on the right level, on the level of plurality.

> (interviewer speaks)

### Audrey Tang:

Doesn't openness make one more vulnerable to attacks?

Yes and no. I mean, there are attacks that are adversarial, meaning that they want to achieve a strategic goal, but there are also friendly attacks, like penetration testers, white hat hackers, people who want to help you.

So as long as you do the openness in a properly staged way, like first opening in a sandbox or even a honeypot, and then opening through a pilot testing, opening through bug bounty, opening through some ways to incentivize the white hat hackers to work with you, rather than the black hats that work against you, then openness actually make you less vulnerable to attacks.

This is why Linux is easier to harden. If you work on security-enhanced Linux, many Linux variants that focus on security, it's much easier because you do not have to be Linux robots to make such enhancements. Everybody can attack Linux and see its weak points and also improve on it.

But if you just do openness without doing collaboration, then it does make you more vulnerable to attacks because you don't benefit from your collaborators working with you to make your move secure. We need to plan openness with participation and an accountable way to get democratic input, including white hat input.

And if you don't do that and just put it on GitHub, of course it makes you more vulnerable to attacks. I hope that answers the question.

> (interviewer speaks)

### Audrey Tang:

Certainly. Back in 2010, I publicly said that my consultation rate at the time was one Bitcoin per hour, which sounds astronomical now, but back then it was just 100 euros or 200 euros.

And so the large companies that I work with, none of them processed Bitcoin. So they just look at the BTC index and translate to fiat and pay me that much fiat. But I was a very early Bitcoin advocate.

At the time, its carbon footprint was negligible because not many people use it. But as Bitcoin started to gain adoption and as I publicly burned my wallets joining the cabinet in 2016, I see more and more of the environmental impacts of that.

When Vitalik Buterin, co-founder of Ethereum, visited me in 2016, the main thing we talked about was actually the climate crisis and how the urgency of the climate situation promotes societal changes and how the blockchain community can make a good fork, instead of a bad fork that makes issues worse.

Since then, we very happily saw that Vitalik and his teams successfully migrated Ethereum to proof-of-stake and thereby massively reducing their environmental issues. Then I publicly said that I'm not going to use any proo-of-work coins.

Now I'm on Ethereum and Tezos, but I'm not on Bitcoin anymore, which was actually a difficult choice for me to make back then, because I was, as some of you know, a conservative anarchist and believed in the ability of code to reorganize society.

However, even if we reorganize society to our liking, if we destroy the planet, it's all for nothing.

So I made this conversation with myself many years ago, and I'm now very firmly taking care of the planet before even the people. I hope this answers the question.

> (interviewer speaks)

### Audrey Tang:

Oh yeah, definitely. Because as you can see from this background, the IT makes visualizing the entire globe easier than usual.

Using latest satellite technology, we can easily verify whether people who promise a carbon sink, a forest here, a garden somewhere, are actually delivering the work.

You can even easily quantify the environmental impact, which would be impossible without some AI and some digital and communication technology.

So this is just one example, but it does give people a sort of overview effect. It's like flying to the International Space Station and see the Earth as one holistic object. And I firmly believe when we get people to that mindset, it does make working on societal challenges on a planet scale much easier, because then we work on the same object.

If we just stay on this short-termism and look not above the clouds, then everybody is trapped on our own plot of land. So, to promote holistic thinking and use data-generated evidence for international coordination, I think this is the main way that digital technologies can help.

> (interviewer speaks)

### Audrey Tang:

There is a new question on Slido. Let's switch back to that.

Is it possible that the administrative task of a city, region, or a nation can be gradually, at least in part, taken over by an artificial intelligence, because it's more competent, more neutral, and less corruptible?

Well, then it would also be more centralized, and I'm not sure whether that is a good idea. Because when we say AI, I prefer "assistive intelligence" rather than artificial intelligence or authoritarian intelligence.

And the main difference is whether it empowers everyday citizens, people closer to the pain, or whether it just empowers the experts or the people with the most GPUs.

I mentioned that I do my language model training on my own laptop. I do believe in edge AI, local AI, open source ones at that, because it gives control to the citizens, to the people benefiting from the AI, and everybody can tune it the way their norms dictate instead of what the monoculture somewhere in Silicon Valley dictates.

I often say this assistive way of looking at AI is like my eyeglasses, which is an assistive technology.

It's very transparent: It lets me see you more clearly, but it doesn't push advertisement to my retina.

It's very accountable: If there is bias, that is to say if it's blurry or it's skewed, I just fix it myself using some super glue. I actually did that a few months ago. Or bring it to the repair shop down the street. We don't have to reverse engineer or to sign an NDA and pay millions of euros or whatever. An assistive technology puts paramount importance on the dignity of the person or the community that it's assisting.

I think we can actually take the governance issue by putting what we call the overview effect to entire city or entire society, but with each person's assistive AI helping them to comprehend this wicked problem and people's positions and things like that.

Once we have that, then it's much easier for us to talk about societal issues in a way that respects people's preferences instead of just a single authoritarian AI training things. So this is my position.

Now the next question, "I was really interested in what you said about Facebook and potential impact on democracy. For example, Cambridge Analytica. Don't you think it can be used to jeopardize democracy?" 

Yes. It not only can be used, it has been used to jeopardize democracies. It's very well documented.

I think that was because many democratic jurisdictions were confusing Facebook with the public square.

A public square is something that's in the social sector that people administer together and co-govern.

At the end of the day, Facebook is a platform for advertising and entertainment

And so it will be like, we try to hold a town hall, our local pub where people drink, it's very rowdy, very loud. A lot of people selling merchandise. There's private bouncers escorting you out if you say something against the bars rules or whatever.

Then you say our town hall doesn't function very well here... of course, because that's not the place you hold town halls.

So I think it's a symptom, not necessarily a root cause, because in Taiwan we saw that if you have invested in digital public infrastructure, in the town halls and campuses and museums of the digital world, and you allocate the same kind of funding as you would for public libraries and museums in the real world and parks in the real world, then actually people understand Facebook is where you go for quick laughs and cute cats or whatever.

But the Join platform and open data platform, the platforms of binding power, reside in the `gov.tw` or `org.tw` internet domains.

> (interviewer speaks)

### Audrey Tang:

Thank you so much.

